{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model # type: ignore\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout # type: ignore\n",
    "from keras.optimizers import Adam # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"  # The set of valid characters\n",
    "max_str_len = 50                             # Maximum length of input labels\n",
    "num_of_characters = len(alphabets) + 1       # Number of unique characters, plus 1 for CTC pseudo-blank\n",
    "num_of_timestamps = 64   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model_weight = 'trained_model_13_3.h5' # the best model weight\n",
    "#path_to_model_weight = 'trained_model_12_3.h5' # previous version\n",
    "\n",
    "\n",
    "# Define the input layer with a shape of (256, 64, 1) for grayscale images\n",
    "input_data = Input(shape=(256, 64, 1), name='input')\n",
    "\n",
    "# Convolutional Layer 1: 32 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)\n",
    "inner = BatchNormalization()(inner)  # Batch normalization\n",
    "inner = Activation('relu')(inner)  # ReLU activation\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # Max-pooling\n",
    "\n",
    "# Convolutional Layer 2: 64 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# Convolutional Layer 3: 128 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# Reshape the output for sequence processing\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "\n",
    "# Fully Connected Layer 1: 64 units, ReLU activation, He normal initialization\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "# Bidirectional LSTM Layers: 256 units, return sequences\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm2')(inner)\n",
    "\n",
    "# Output Layer: Number of characters, He normal initialization\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal', name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)  # Softmax activation\n",
    "# Create the model with input and output layers\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "\n",
    "model.load_weights(path_to_model_weight)\n",
    "\n",
    "# The ctc loss function\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # The 2 is critical here since the first couple outputs of the RNN tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# Define input placeholders for true labels, input sequence length, and label sequence length\n",
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "# Calculate CTC loss using the ctc_lambda_func function\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "# Create the final model that takes input data, true labels, input length, and label length\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)\n",
    "# Compile the final model with a dummy loss lambda function (loss calculation occurs elsewhere)\n",
    "# The optimizer used is Adam with a learning rate of 0.0001\n",
    "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(learning_rate=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to preprocess the img\n",
    "def preprocess(img):\n",
    "    (h, w) = img.shape                                    # Getting the height & width of the image\n",
    "    \n",
    "    final_img = np.ones([64, 256])*255                    # Blank white image\n",
    "    \n",
    "    # crop    \n",
    "    if h > 64:\n",
    "        img = img[:64, :]                                 # If the h>64 then it is cropped to 64\n",
    "        \n",
    "    if w > 256:\n",
    "        img = img[:, :256]                                # If the w>256 then it is cropped to 256\n",
    "    \n",
    "    final_img[:h, :w] = img\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE) # Rotate 90Â° Clockwise & return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_num(label):\n",
    "    return np.array([alphabets.find(ch) for ch in label])\n",
    "\n",
    "\n",
    "def num_to_label(num):\n",
    "    return ''.join([alphabets[ch] for ch in num if ch != -1])\n",
    "\n",
    "blank_label = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(image, target_size=(64, 256)):\n",
    "    (h, w) = image.shape\n",
    "    target_h, target_w = target_size\n",
    "    \n",
    "    scale = min(target_h / h, target_w / w)  # Calculate scale to fit target size\n",
    "    new_h = int(h * scale)\n",
    "    new_w = int(w * scale)\n",
    "    \n",
    "    resized_img = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)  # Resize while preserving aspect ratio\n",
    "    final_img = np.ones((target_h, target_w)) * 255  # Blank white image of target size\n",
    "    final_img[:new_h, :new_w] = resized_img  # Place resized image in top-left corner\n",
    "    \n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "    image = preprocess(image)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    # Reshape the image to have a batch size of 1\n",
    "    image = image.reshape(1, 256, 64, 1)\n",
    "    \n",
    "    pred = model.predict(image)\n",
    "    decoded = tf.keras.backend.get_value(\n",
    "        tf.keras.backend.ctc_decode(pred, input_length=np.ones(pred.shape[0]) * pred.shape[1], greedy=True)[0][0]\n",
    "    )\n",
    "    \n",
    "    return num_to_label(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_prediction(image, window_size=(64, 256), step_size=128):\n",
    "    (h, w) = image.shape\n",
    "    \n",
    "    if h < window_size[0]:  # Pad height if it's smaller than 64\n",
    "        padding_h = window_size[0] - h\n",
    "        image = np.pad(image, ((0, padding_h), (0, 0)), 'constant', constant_values=255)\n",
    "    \n",
    "    if w < window_size[1]:  # Pad width if it's smaller than 256\n",
    "        padding_w = window_size[1] - w\n",
    "        image = np.pad(image, ((0, 0), (0, padding_w)), 'constant', constant_values=255)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for x in range(0, w - window_size[1] + 1, step_size):  # Slide window horizontally\n",
    "        window = image[:, x:x + window_size[1]]  # Extract the window\n",
    "        pred_text = predict(window)  # Predict text in the window\n",
    "        results.append(pred_text)  \n",
    "    \n",
    "    return ''.join(results)  # Combine predictions from all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_fixed_size(image, target_size=(64, 256)):\n",
    "    (h, w) = image.shape\n",
    "    target_h, target_w = target_size\n",
    "    \n",
    "    if h > target_h:  # Crop height if larger than target\n",
    "        image = image[:target_h, :]\n",
    "    \n",
    "    final_img = np.ones(target_size) * 255  # Blank white image\n",
    "    final_img[:h, :w] = image  # Place original image in top-left corner\n",
    "    \n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_image(image, part_width=256):\n",
    "    (h, w) = image.shape\n",
    "    results = []\n",
    "    \n",
    "    for start_x in range(0, w, part_width):  # Divide image into sub-images\n",
    "        part_img = image[:, start_x:start_x + part_width]  # Extract part of the image\n",
    "        padded_img = pad_image_to_fixed_size(part_img)  # Pad to fixed size (64, 256)\n",
    "        pred_text = predict(padded_img)  # Predict text for the sub-image\n",
    "        results.append(pred_text)  \n",
    "    \n",
    "    return ''.join(results)  # Combine predictions from all sub-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(image,text):\n",
    "    if(text[-4:]== 'EPTY'):\n",
    "        text = text[:-4]\n",
    "\n",
    "    image = mpimg.imread(image)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Menyembunyikan axis\n",
    "    plt.show()\n",
    "\n",
    "    print(\"predicted:\",text)\n",
    "    print(\"len:\",len(text))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0\n",
      "prepared image to analyse\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: TOUNADE NO BAAECHAN KATA UZLMAKI NARUTO\n",
      "len: 39\n",
      "\n",
      "index 1\n",
      "prepared image to analyse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@4.811] global loadsave.cpp:241 findDecoder imread_('./test_v2/test/Capital/37-41/TEST_1.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test_v2/test/Capital/37-41/TEST_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(name, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)  \u001b[38;5;66;03m# Read grayscale image\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m result_text \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_large_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m postprocess(name,result_text)\n",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m, in \u001b[0;36mprocess_large_image\u001b[0;34m(image, part_width)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_large_image\u001b[39m(image, part_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     (h, w) \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m      3\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m start_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, w, part_width):  \u001b[38;5;66;03m# Divide image into sub-images\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#1-4\n",
    "for i in range(0,3):\n",
    "    print(f'index {i}')\n",
    "    print('prepared image to analyse')\n",
    "    name = f'./test_v2/test/Capital/37-41/TEST_{i}.png'\n",
    "    image = cv2.imread(name, cv2.IMREAD_GRAYSCALE)  # Read grayscale image\n",
    "    result_text = process_large_image(image)\n",
    "    postprocess(name,result_text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'TSUNADE NO BAACHAN KATA NARUTO UZUMAKI'\n",
    "print(len(string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
