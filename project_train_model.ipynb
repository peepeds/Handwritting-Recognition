{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372c45910172988d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Making Model\n",
    "- This Model is build using python 3.8.10\n",
    "- different version of python can be impact to the erroneous of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "169b1bb87796080e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:43:46.970921400Z",
     "start_time": "2024-05-10T15:43:36.637867400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Warning python version < 3.12.0( 3.8.10 recommended)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from setuptools import setup # use instead of distutils(deprecated)\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f6da28a7fe94b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:12:01.060665100Z",
     "start_time": "2024-05-10T15:12:01.031672900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices(\"CPU\"))\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21106f9dcd4529",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abfe2ffc26e0b500",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:33.902460800Z",
     "start_time": "2024-05-10T15:55:33.525110800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  0.80  330961\n",
      "valid data:  0.10  41370\n",
      "test data:   0.10  41370\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./archive/written_name_train_v2.csv')\n",
    "valid = pd.read_csv('./archive/written_name_validation_v2.csv')\n",
    "test = pd.read_csv('./archive/written_name_test_v2.csv')\n",
    "\n",
    "train_len = len(train)\n",
    "test_len = len(test)\n",
    "validation_len = len(valid)\n",
    "\n",
    "sum = train_len + test_len + validation_len\n",
    "\n",
    "print(\"train data:  {:.2f}  {}\".format((train_len/ sum), train_len))\n",
    "print(\"valid data:  {:.2f}  {}\".format((validation_len / sum), validation_len))\n",
    "print(\"test data:   {:.2f}  {}\".format((test_len / sum), test_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92035066333902b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa49dc89895cf8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:35.275255600Z",
     "start_time": "2024-05-10T15:55:34.714657100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(2, 2, i+1)\n",
    "    img_dir = './test_v2/test/' + test.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(test.loc[i, 'IDENTITY'], fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4, hspace=-0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d441f73b5de3d0b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0de0131685133b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:35.536438700Z",
     "start_time": "2024-05-10T15:55:35.464945800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of NaNs in train set      : \", train.IDENTITY.isna().sum())\n",
    "print(\"Number of NaNs in validation set : \", valid.IDENTITY.isna().sum())\n",
    "print(\"Number of NaNs in validation set : \", test.IDENTITY.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a067cd2967a115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:35.755766800Z",
     "start_time": "2024-05-10T15:55:35.697992900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the NaNs labels\n",
    "train.dropna(axis=0, inplace=True)\n",
    "valid.dropna(axis=0, inplace=True)\n",
    "test.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b1c06172eee12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:36.032612500Z",
     "start_time": "2024-05-10T15:55:35.967140400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the Unreadable labels\n",
    "train = train[train.IDENTITY != 'UNREADABLE']\n",
    "valid = valid[valid.IDENTITY != 'UNREADABLE']\n",
    "test = test[test.IDENTITY != 'UNREADABLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71280832984128fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:36.341213600Z",
     "start_time": "2024-05-10T15:55:36.243144700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Covert lowercase to uppercase\n",
    "train.IDENTITY = train.IDENTITY.str.upper()\n",
    "valid.IDENTITY = valid.IDENTITY.str.upper()\n",
    "test.IDENTITY = test.IDENTITY.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41644c95dd1ba674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:36.769044200Z",
     "start_time": "2024-05-10T15:55:36.729736900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "train.reset_index(inplace = True, drop=True)\n",
    "valid.reset_index(inplace = True, drop=True)\n",
    "test.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6890a67c661c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:57:19.129900900Z",
     "start_time": "2024-05-10T21:57:19.076641700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = len(train)# train 5000 images \n",
    "#test_size = len(test)\n",
    "valid_size = 5000#len(valid)# train 620 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b0ffa2c33dfca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:38.603350300Z",
     "start_time": "2024-05-10T15:55:38.557475600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_batch_size = 620\n",
    "train_batch_size = 5000\n",
    "print(train_size, valid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6917a061eb35867f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4038097a36882cba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:52:31.914149200Z",
     "start_time": "2024-05-10T15:52:31.884491300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fuction to preprocess the img\n",
    "def preprocess(img):\n",
    "    (h, w) = img.shape                                    # Getting the height & width of the image\n",
    "    \n",
    "    final_img = np.ones([64, 256])*255                    # Blank white image\n",
    "    \n",
    "    # crop    \n",
    "    if h > 64:\n",
    "        img = img[:64, :]                                 # If the h>64 then it is cropped to 64\n",
    "        \n",
    "    if w > 256:\n",
    "        img = img[:, :256]                                # If the w>256 then it is cropped to 256\n",
    "    \n",
    "    final_img[:h, :w] = img\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE) # Rotate 90Â° Clockwise & return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0bfaaccda6186c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Preprocess & save test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae99bb67c9788a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T11:58:24.748235500Z",
     "start_time": "2024-05-10T11:14:44.726510300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "\n",
    "for i in range(train_size):\n",
    "    img_dir = './archive//train_v2/train/' + train.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    train_x.append(image)\n",
    "    \n",
    "    if (i + 1) % 10000 == 0:\n",
    "        print(f\"Processed {i + 1} images\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38f888fea656ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T19:11:42.910616900Z",
     "start_time": "2024-04-27T19:06:43.638387700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the train_x array into batches of train_batch_size images each\n",
    "batch_size = train_batch_size\n",
    "num_batches = len(train_x) // batch_size\n",
    "remainder = len(train_x) % batch_size\n",
    "\n",
    "start_idx = 0\n",
    "for i in range(num_batches):\n",
    "    end_idx = start_idx + batch_size\n",
    "    # Extract a batch of images\n",
    "    batch_images = train_x[start_idx:end_idx]\n",
    "    # Reshape the batch into the required format (num_images, height, width, channels)\n",
    "    batch_images = np.array(batch_images).reshape(-1, 256, 64, 1)\n",
    "\n",
    "    # Create a folder for the current batch\n",
    "    folder_path = os.path.join('dataset', f'{i + 1}')\n",
    "\n",
    "    # Save the batch to a .npy file\n",
    "    filename = os.path.join(folder_path, f'train_x.npy')\n",
    "    np.save(filename, batch_images)\n",
    "\n",
    "    start_idx = end_idx\n",
    "    \n",
    "    print(i+1)\n",
    "\n",
    "# Process the remaining images\n",
    "if remainder > 0:\n",
    "    # Extract the remaining images\n",
    "    batch_images = train_x[start_idx:]\n",
    "    # Reshape the remaining images into the required format\n",
    "    batch_images = np.array(batch_images).reshape(-1, 256, 64, 1)\n",
    "    # Create a folder for the remaining images\n",
    "    folder_path = os.path.join('dataset', f'{num_batches + 1}')\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    # Save the remaining images to a .npy file\n",
    "    filename = os.path.join(folder_path, f'train_x.npy')\n",
    "    np.save(filename, batch_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6988fdd9c7323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:53:59.226380300Z",
     "start_time": "2024-05-10T15:52:38.491048800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert 'train_x' to a NumPy array and reshape it\n",
    "#train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n",
    "\n",
    "#np.save('preprocessed_train_v2', train_x)\n",
    "train_x = np.load('preprocessed_train_v2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846065b57d8909ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Preprocess & save valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9e9a001aedbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:58:13.906009700Z",
     "start_time": "2024-05-10T21:57:42.642819700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_x = []\n",
    "\n",
    "for i in range(valid_size):\n",
    "    img_dir = '.archive/validation_v2/validation/' + valid.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    valid_x.append(image)\n",
    "    \n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Processed {i + 1} images\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c50f86f01d399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T18:19:25.486302Z",
     "start_time": "2024-04-27T18:19:18.917715500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the valid_x array into batches of valid_batch_size images each\n",
    "batch_size = valid_batch_size\n",
    "num_batches = len(valid_x) // batch_size\n",
    "remainder = len(valid_x) % batch_size\n",
    "\n",
    "start_idx = 0\n",
    "for i in range(num_batches):\n",
    "    end_idx = start_idx + batch_size\n",
    "    # Extract a batch of images\n",
    "    batch_images = valid_x[start_idx:end_idx]\n",
    "    # Reshape the batch into the required format (num_images, height, width, channels)\n",
    "    batch_images = np.array(batch_images).reshape(-1, 256, 64, 1)\n",
    "\n",
    "    # Create a folder for the current batch\n",
    "    folder_path = os.path.join('dataset', f'{i + 1}')\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Save the batch to a .npy file\n",
    "    filename = os.path.join(folder_path, f'valid_x.npy')\n",
    "    np.save(filename, batch_images)\n",
    "\n",
    "    start_idx = end_idx\n",
    "\n",
    "    print(i+1)\n",
    "# Process the remaining images\n",
    "if remainder > 0:\n",
    "    # Extract the remaining images\n",
    "    batch_images = valid_x[start_idx:]\n",
    "    # Reshape the remaining images into the required format\n",
    "    batch_images = np.array(batch_images).reshape(-1, 256, 64, 1)\n",
    "    # Create a folder for the remaining images\n",
    "    folder_path = os.path.join('dataset', f'{num_batches + 1}')\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    # Save the remaining images to a .npy file\n",
    "    filename = os.path.join(folder_path, f'valid_x.npy')\n",
    "    np.save(filename, batch_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69d27dc025d9e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:58:19.319876100Z",
     "start_time": "2024-05-10T21:58:18.957504900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert 'valid_x' to a NumPy array and reshape it\n",
    "valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)\n",
    "# np.save('preprocessed_validation_v2', valid_x)\n",
    "#valid_x = np.load('preprocessed_validation_v2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587adc96df668f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Label Preprocess\n",
    "In this section of the code, we perform data label preprocessing for a text recognition task. The goal is to convert text labels into a numerical format for use in train a neural network. Let's break down the key components of this preprocess:\n",
    "\n",
    "Character Set and Constants\n",
    "* alphabets: This string represents the set of valid characters that can appear in the text labels. It includes uppercase letters, hyphen, and space.\n",
    "\n",
    "* max_str_len: This constant defines the maximum length of the input labels.\n",
    "\n",
    "* num_of_characters: The number of unique characters, including an extra one for the CTC pseudo-blank character.\n",
    "\n",
    "* num_of_timestamps: The maximum length of predicted labels.\n",
    "\n",
    "# Label-to-Number Conversion\n",
    "* label_to_num(label): This function converts a text label to a numerical representation. It initializes an empty list to store character indices and iterates over each character in the input label. For each character, it finds the index in the alphabets string and appends it to the list. The function returns a NumPy array with the numerical representation of the label.\n",
    "* Number-to-Label Conversion\n",
    "num_to_label(num): This function converts a list of numerical values back to a text label. It iterates over each character index in the input list, checks for the CTC blank character (-1), and appends the corresponding character from alphabets to the output string.\n",
    "\n",
    "# Initialization of Arrays\n",
    "Several arrays are initialized to store the preprocessed labels and related information for both training and validation datasets. These include:\n",
    "\n",
    "* train_y: An array to store the converted labels for the training dataset.\n",
    "\n",
    "* train_label_len: An array to store the length of labels for each data point in the training dataset.\n",
    "\n",
    "* train_input_len: An array to store the input length for each data point in the training dataset.\n",
    "\n",
    "* train_output: An array to store training data outputs (usually used for CTC loss).\n",
    "\n",
    "# Data Processing\n",
    "A loop is used to process both the training and validation datasets. Within the loop:\n",
    "\n",
    "* The 'IDENTITY' value from the dataset is retrieved and converted to a string if it's not already.\n",
    "\n",
    "* The label length is set and label values are stored in the corresponding arrays (train_y for training and valid_y for validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684daf84ae57ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:47.288102300Z",
     "start_time": "2024-05-10T15:55:47.259087900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphabets = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"  # The set of valid characters\n",
    "max_str_len = 34                             # Maximum length of input labels\n",
    "num_of_characters = len(alphabets) + 1       # Number of unique characters, plus 1 for CTC pseudo-blank\n",
    "num_of_timestamps = 64                       # The maximum length of predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14ba8429529fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:47.596985200Z",
     "start_time": "2024-05-10T15:55:47.577954200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label_to_num(label):\n",
    "    return np.array([alphabets.find(ch) if ch in alphabets else 27 for ch in label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e4a58d6893a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:47.937390500Z",
     "start_time": "2024-05-10T15:55:47.881474900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def num_to_label(num):\n",
    "    return ''.join([alphabets[ch] for ch in num if ch != -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6770bc6f5763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:48.258050900Z",
     "start_time": "2024-05-10T15:55:48.211433Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "name = 'TATIA'\n",
    "name_num = label_to_num(name)\n",
    "print(name_num,'\\n', num_to_label(name_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d77849f8a66a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:49.954584500Z",
     "start_time": "2024-05-10T15:55:49.907825200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blank_label = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0738200ef911a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:55.163754900Z",
     "start_time": "2024-05-10T15:55:50.418470200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize arrays\n",
    "train_y = np.ones([train_size, max_str_len]) * blank_label\n",
    "train_label_len = np.zeros([train_size, 1])\n",
    "train_input_len = np.ones([train_size, 1]) * (num_of_timestamps - 2)\n",
    "train_output = np.zeros([train_size])\n",
    "\n",
    "# Loop through the training data\n",
    "for i in range(train_size):\n",
    "    # Get the 'IDENTITY' value and convert it to a string if it's not already\n",
    "    identity = train.loc[i, 'IDENTITY']\n",
    "    if not isinstance(identity, str):\n",
    "        identity = str(identity)\n",
    "    \n",
    "    # Set the label length and label values in train_y\n",
    "    train_label_len[i] = len(identity)\n",
    "    \n",
    "    # Assuming label_to_num is a function that converts characters to numerical values\n",
    "    train_y[i, 0:len(identity)] = label_to_num(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8064b1333c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T21:01:40.463793100Z",
     "start_time": "2024-04-27T21:01:35.952215Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = train_batch_size\n",
    "\n",
    "# Iterate through each folder\n",
    "for i in range(1, 67):\n",
    "    folder_path = os.path.join('dataset', str(i))\n",
    "\n",
    "    batch_train_y = np.ones([batch_size, max_str_len]) * blank_label\n",
    "    batch_train_label_len = np.zeros([batch_size, 1])\n",
    "    batch_train_input_len = np.ones([batch_size, 1]) * (num_of_timestamps - 2)\n",
    "    batch_train_output = np.zeros([batch_size])\n",
    "    \n",
    "    # Loop through the training data\n",
    "    for j in range(batch_size):\n",
    "        # Get the 'IDENTITY' value and convert it to a string if it's not already\n",
    "        identity = train.loc[(batch_size * (i-1)) + j, 'IDENTITY']\n",
    "        if not isinstance(identity, str):\n",
    "            identity = str(identity)\n",
    "        \n",
    "        # Set the label length and label values in train_y\n",
    "        batch_train_label_len[j] = len(identity)\n",
    "        \n",
    "        # Assuming label_to_num is a function that converts characters to numerical values\n",
    "        batch_train_y[j, 0:len(identity)] = label_to_num(identity)\n",
    "\n",
    "    # Save data in the folder\n",
    "    np.save(os.path.join(folder_path, 'train_y.npy'), batch_train_y)\n",
    "    np.save(os.path.join(folder_path, 'train_label_len.npy'), batch_train_label_len)\n",
    "    np.save(os.path.join(folder_path, 'train_input_len.npy'), batch_train_input_len)\n",
    "    np.save(os.path.join(folder_path, 'train_output.npy'), batch_train_output)\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db3c237dc66b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:59.670719700Z",
     "start_time": "2024-05-10T15:55:58.940383300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize arrays for validation data\n",
    "valid_y = np.ones([valid_size, max_str_len]) * blank_label\n",
    "valid_label_len = np.zeros([valid_size, 1])\n",
    "valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps - 2)\n",
    "valid_output = np.zeros([valid_size])\n",
    "\n",
    "# Loop through the validation data\n",
    "for i in range(valid_size):\n",
    "    # Get the 'IDENTITY' value and convert it to a string if it's not already\n",
    "    identity = valid.loc[i, 'IDENTITY']\n",
    "    if not isinstance(identity, str):\n",
    "        identity = str(identity)\n",
    "    \n",
    "    # Set the label length and label values in valid_y\n",
    "    valid_label_len[i] = len(identity)\n",
    "    \n",
    "    # Assuming label_to_num is a function that converts characters to numerical values\n",
    "    valid_y[i, 0:len(identity)] = label_to_num(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18775aa647d718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T21:01:53.585874100Z",
     "start_time": "2024-04-27T21:01:52.898024Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = valid_batch_size\n",
    "\n",
    "# Iterate through each folder\n",
    "for i in range(1, 67):\n",
    "    folder_path = os.path.join('dataset', str(i))\n",
    "\n",
    "    batch_valid_y = np.ones([batch_size, max_str_len]) * blank_label\n",
    "    batch_valid_label_len = np.zeros([batch_size, 1])\n",
    "    batch_valid_input_len = np.ones([batch_size, 1]) * (num_of_timestamps - 2)\n",
    "    batch_valid_output = np.zeros([batch_size])\n",
    "    \n",
    "    # Loop through the training data\n",
    "    for j in range(batch_size):\n",
    "        # Get the 'IDENTITY' value and convert it to a string if it's not already\n",
    "        identity = valid.loc[((batch_size * (i-1)) + j), 'IDENTITY']\n",
    "        if not isinstance(identity, str):\n",
    "            identity = str(identity)\n",
    "        # Set the label length and label values in train_y\n",
    "        batch_valid_label_len[j] = len(identity)\n",
    "        \n",
    "        # Assuming label_to_num is a function that converts characters to numerical values\n",
    "        batch_valid_y[j, 0:len(identity)] = label_to_num(identity)\n",
    "\n",
    "    # Save data in the folder\n",
    "    np.save(os.path.join(folder_path, 'valid_y.npy'), batch_valid_y)\n",
    "    np.save(os.path.join(folder_path, 'valid_label_len.npy'), batch_valid_label_len)\n",
    "    np.save(os.path.join(folder_path, 'valid_input_len.npy'), batch_valid_input_len)\n",
    "    np.save(os.path.join(folder_path, 'valid_output.npy'), batch_valid_output)\n",
    "    \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c763ea49f901173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:09:34.471170500Z",
     "start_time": "2024-05-10T14:09:34.425718800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('True label : ',train.loc[4, 'IDENTITY'] , '\\ntrain_y : ',train_y[4],'\\ntrain_label_len : ',train_label_len[4], \n",
    "      '\\ntrain_input_len : ', train_input_len[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878a145a6249dc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:03:40.048432200Z",
     "start_time": "2024-05-10T22:03:38.693075900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the input layer with a shape of (256, 64, 1) for grayscale images\n",
    "input_data = Input(shape=(256, 64, 1), name='input')\n",
    "\n",
    "# Convolutional Layer 1: 32 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)\n",
    "inner = BatchNormalization()(inner)                         # Batch normalization\n",
    "inner = Activation('relu')(inner)                           # ReLU activation\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # Max-pooling\n",
    "\n",
    "# Convolutional Layer 2: 64 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)  \n",
    "inner = Activation('relu')(inner)     \n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  \n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# Convolutional Layer 3: 128 filters, (3, 3) kernel, 'same' padding, He normal initialization\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)                         \n",
    "inner = Activation('relu')(inner)                           \n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  \n",
    "inner = Dropout(0.3)(inner)                                 \n",
    "\n",
    "# Reshape the output for sequence processing\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "\n",
    "# Fully Connected Layer 1: 64 units, ReLU activation, He normal initialization\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "# Bidirectional LSTM Layers: 256 units, return sequences\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm2')(inner)\n",
    "\n",
    "# Output Layer: Number of characters, He normal initialization\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal', name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)  # Softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f381ac8fbc3c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:03:40.231987700Z",
     "start_time": "2024-05-10T22:03:40.081920300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the model with input and output layers\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "\n",
    "model.load_weights('checkpoints/model_14_1.221.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481950c35aae076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:03:40.378869400Z",
     "start_time": "2024-05-10T22:03:40.192819500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac37d58abffea7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compute the CTC loss between predicted and true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e86bfcbc6592c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:03:41.247470800Z",
     "start_time": "2024-05-10T22:03:41.206117300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The ctc loss function\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # The 2 is critical here since the first couple outputs of the RNN tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936203356a1799f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:03:41.782748600Z",
     "start_time": "2024-05-10T22:03:41.675432900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define input placeholders for true labels, input sequence length, and label sequence length\n",
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "# Calculate CTC loss using the ctc_lambda_func function\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "# Create the final model that takes input data, true labels, input length, and label length\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e283d3f97eb6cd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:03:42.313709900Z",
     "start_time": "2024-05-10T22:03:42.266576Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile the final model with a dummy loss lambda function (loss calculation occurs elsewhere)\n",
    "# The optimizer used is Adam with a learning rate of 0.0001\n",
    "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(learning_rate=0.0001))\n",
    "history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9582ac9094c52",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef03497a68fe7e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T22:05:58.173372200Z",
     "start_time": "2024-04-28T22:05:23.157023800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the folder to save the model\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Define EarlyStopping and ModelCheckpoint callbacks\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)  # Stop training if val_loss does not improve\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'model_{epoch:02d}_{val_loss:.3f}.h5'),  # Path to the model file to be saved\n",
    "    monitor='val_loss',  # Monitor val_loss\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    mode='min'  # Save the model when val_loss is at its minimum\n",
    ")\n",
    "\n",
    "# Iterate through each folder\n",
    "for i in range(0, 67):\n",
    "    folder_path = os.path.join('dataset', str(i))\n",
    "    \n",
    "    # Load data from files in the folder\n",
    "    train_x = np.load(os.path.join(folder_path, 'train_x.npy'))\n",
    "    train_y = np.load(os.path.join(folder_path, 'train_y.npy'))\n",
    "    train_input_len = np.load(os.path.join(folder_path, 'train_input_len.npy'))\n",
    "    train_label_len = np.load(os.path.join(folder_path, 'train_label_len.npy'))\n",
    "    train_output = np.load(os.path.join(folder_path, 'train_output.npy'))\n",
    "\n",
    "    valid_x = np.load(os.path.join(folder_path, 'valid_x.npy'))\n",
    "    valid_y = np.load(os.path.join(folder_path, 'valid_y.npy'))\n",
    "    valid_input_len = np.load(os.path.join(folder_path, 'valid_input_len.npy'))\n",
    "    valid_label_len = np.load(os.path.join(folder_path, 'valid_label_len.npy'))\n",
    "    valid_output = np.load(os.path.join(folder_path, 'valid_output.npy'))\n",
    "\n",
    "    # Train the model with the current data\n",
    "    print(\"dataset \", i)\n",
    "    history_buff = model_final.fit(\n",
    "        x=[train_x, train_y, train_input_len, train_label_len],\n",
    "        y=train_output,\n",
    "        validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stopping_callback, checkpoint_callback]\n",
    "    )\n",
    "    \n",
    "    history.extend(history_buff.history['loss'])\n",
    "    history.extend(history_buff.history['val_loss']) \n",
    "    \n",
    "     # Delete variables to free up memory\n",
    "    del train_x, train_y, train_input_len, train_label_len, train_output\n",
    "    del valid_x, valid_y, valid_input_len, valid_label_len, valid_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3116ce264e223f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T16:21:38.095821100Z",
     "start_time": "2024-05-10T16:21:38.029762100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomDataLoader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.train_input_len = train_input_len\n",
    "        self.train_label_len = train_label_len\n",
    "        self.train_output = train_output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_x) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.train_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.train_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_input_len = self.train_input_len[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_label_len = self.train_label_len[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_output = self.train_output[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    \n",
    "        return ([batch_x, batch_y, batch_input_len, batch_label_len], batch_output)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "batch_size = 32\n",
    "\n",
    "data_loader = CustomDataLoader(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbef25396cfa7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T16:21:40.223807Z",
     "start_time": "2024-05-10T16:21:40.197419100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ValidationDataLoader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, valid_x, valid_y, valid_input_len, valid_label_len, valid_output, batch_size=32):\n",
    "        self.valid_x = valid_x\n",
    "        self.valid_y = valid_y\n",
    "        self.valid_input_len = valid_input_len\n",
    "        self.valid_label_len = valid_label_len\n",
    "        self.valid_output = valid_output\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_x) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = (idx + 1) * self.batch_size\n",
    "        batch_x = self.valid_x[start_idx:end_idx]\n",
    "        batch_y = self.valid_y[start_idx:end_idx]\n",
    "        batch_input_len = self.valid_input_len[start_idx:end_idx]\n",
    "        batch_label_len = self.valid_label_len[start_idx:end_idx]\n",
    "        batch_output = self.valid_output[start_idx:end_idx]\n",
    "        return ([batch_x, batch_y, batch_input_len, batch_label_len], batch_output)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "valid_loader = ValidationDataLoader(valid_x, valid_y, valid_input_len, valid_label_len, valid_output, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e56964688825ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T23:00:08.890663Z",
     "start_time": "2024-05-09T22:43:23.977807700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save DataLoader\n",
    "with open('data_loader.pkl', 'wb') as f:\n",
    "    pickle.dump(data_loader, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5366681093de83",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-10T08:34:29.700373500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load DataLoader\n",
    "with open('data_loader.pkl', 'rb') as f:\n",
    "    loaded_data_loader = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa346224a309f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T14:41:47.133567800Z",
     "start_time": "2024-05-10T14:41:45.307122100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_data = data_loader.get_validation_data(batch_size=32)\n",
    "x_data, y_data = validation_data[0], validation_data[1]\n",
    "\n",
    "for data_array in x_data:\n",
    "    print(\"Shape of data array:\", data_array.shape)\n",
    "\n",
    "print(\"Shape of output array:\", y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18519fa4ef9a2934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:53:28.511601300Z",
     "start_time": "2024-05-10T16:21:54.972215400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints/'\n",
    "# Define EarlyStopping and ModelCheckpoint callbacks\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)  # Stop training if val_loss does not improve\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'model_{epoch:02d}_{val_loss:.3f}.h5'),  # Path to the model file to be saved\n",
    "    monitor='val_loss',  # Monitor val_loss\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    mode='min'  # Save the model when val_loss is at its minimum\n",
    ")\n",
    "\n",
    "\n",
    "history = model_final.fit(data_loader,\n",
    "                          validation_data= valid_loader,\n",
    "                          epochs=80,\n",
    "                          callbacks=[early_stopping_callback, checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238d4ac65c863ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:53:32.717535500Z",
     "start_time": "2024-05-10T21:53:32.441943800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  loss and val_loss history\n",
    "loss = history[::2]\n",
    "val_loss = history[1::2]\n",
    "\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92960f55a9fa312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:06:04.052845100Z",
     "start_time": "2024-05-10T22:06:03.959577Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model \n",
    "model.save('trained_model_14_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def6b3b95001eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T20:35:52.602898100Z",
     "start_time": "2024-04-28T20:35:52.577883900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save history\n",
    "with open('history12.pkl', 'wb') as file:\n",
    "    pickle.dump(history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54826faceca976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:02:51.756810500Z",
     "start_time": "2024-05-10T22:02:49.826817400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load model\n",
    "model = load_model('trained_model.h12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb17b9a3d9fb89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:04:03.107742Z",
     "start_time": "2024-05-10T22:03:55.353133500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = model.predict(valid_x)\n",
    "decoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n",
    "                                   greedy=True)[0][0])\n",
    "\n",
    "prediction = []\n",
    "for i in range(valid_size):\n",
    "    prediction.append(num_to_label(decoded[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e07dacd55e2856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:04:06.228065200Z",
     "start_time": "2024-05-10T22:04:06.185321100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = valid.loc[0:valid_size, 'IDENTITY']\n",
    "correct_char = 0\n",
    "total_char = 0\n",
    "correct = 0\n",
    "\n",
    "for i in range(valid_size):\n",
    "    pr = prediction[i]\n",
    "    tr = y_true[i]\n",
    "    total_char += len(tr)\n",
    "    \n",
    "    for j in range(min(len(tr), len(pr))):\n",
    "        if tr[j] == pr[j]:\n",
    "            correct_char += 1\n",
    "            \n",
    "    if pr == tr :\n",
    "        correct += 1 \n",
    "\n",
    "print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n",
    "print('Correct words predicted      : %.2f%%' %(correct*100/valid_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fbeeaedfd174e1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031b3a1770a15b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:54:45.759001600Z",
     "start_time": "2024-05-10T21:54:41.614745800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('written_name_test_v2.csv')\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(6):\n",
    "    ax = plt.subplot(2, 3, i+1)\n",
    "    img_dir = './test_v2/test/'+ test.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    image = preprocess(image)\n",
    "    image = image/255.\n",
    "    pred = model.predict(image.reshape(1, 256, 64, 1))\n",
    "    decoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n",
    "                                       greedy=True)[0][0])\n",
    "    plt.title(num_to_label(decoded[0]), fontsize=12)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0f9643538784a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:05:14.225792700Z",
     "start_time": "2024-05-10T22:04:42.931165600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize variables to track correct characters\n",
    "correct_characters = 0\n",
    "total_characters = 0\n",
    "max_images = 300  # Specify the number of images to evaluate\n",
    "\n",
    "# Iterate through the test set\n",
    "for i in range(min(len(test), max_images)):\n",
    "    # Get the ground truth label\n",
    "    ground_truth = test.loc[i, 'IDENTITY']\n",
    "    \n",
    "    # Preprocess and predict the image using your model\n",
    "    img_dir = './test_v2/test/' + test.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image / 255.0\n",
    "    pred = model.predict(image.reshape(1, 256, 64, 1))\n",
    "    decoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], greedy=True)[0][0])\n",
    "    predicted_label = num_to_label(decoded[0])\n",
    "    \n",
    "     # Calculate character-level accuracy\n",
    "    for j in range(min(len(ground_truth), len(predicted_label))):\n",
    "        if ground_truth[j] == predicted_label[j]:\n",
    "            correct_characters += 1\n",
    "        total_characters += 1\n",
    "        \n",
    "    print(i)\n",
    "\n",
    "# Calculate character-level accuracy\n",
    "character_level_accuracy = (correct_characters / total_characters) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438fb9451fdbe6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T22:05:14.268358Z",
     "start_time": "2024-05-10T22:05:14.227313600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Character-Level Accuracy for {} images: {:.2f}%'.format(max_images, character_level_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12bfaaf982db0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T22:03:43.768367400Z",
     "start_time": "2024-04-28T22:02:48.762067700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to track errors for each character\n",
    "character_errors = {}\n",
    "max_images = 500\n",
    "# Iterate through the test set\n",
    "for i in range(min(len(test), max_images)):\n",
    "    # Get the ground truth label\n",
    "    ground_truth = test.loc[i, 'IDENTITY']\n",
    "    \n",
    "    # Preprocess and predict the image using your model\n",
    "    img_dir = './test_v2/test/' + test.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image / 255.0\n",
    "    pred = model.predict(image.reshape(1, 256, 64, 1))\n",
    "    decoded = tf.keras.backend.get_value(tf.keras.backend.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], greedy=True)[0][0])\n",
    "    predicted_label = num_to_label(decoded[0])\n",
    "    \n",
    "    # Calculate errors for each character\n",
    "    for j in range(min(len(ground_truth), len(predicted_label))):\n",
    "        if ground_truth[j] != predicted_label[j]:\n",
    "            if ground_truth[j] not in character_errors:\n",
    "                character_errors[ground_truth[j]] = 1\n",
    "            else:\n",
    "                character_errors[ground_truth[j]] += 1\n",
    "                \n",
    "# Print characters with the most errors\n",
    "sorted_errors = sorted(character_errors.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Character\\tErrors\")\n",
    "for char, errors in sorted_errors:\n",
    "    print(f\"{char}\\t{errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281afa368e34c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:23:11.235641700Z",
     "start_time": "2024-04-28T21:23:11.170607800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sorted_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce975933691afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:32:36.791463600Z",
     "start_time": "2024-04-28T21:32:22.055463800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "first_12_chars = sorted_errors[0][0][:17]\n",
    "\n",
    "train_indexes = []\n",
    "valid_indexes = []\n",
    "\n",
    "\n",
    "for idx, row in train.iterrows():\n",
    "    count = row['IDENTITY'][:12].count(first_12_chars)\n",
    "    if count > 2:\n",
    "        train_indexes.append(idx)\n",
    "\n",
    "for idx, row in valid.iterrows():\n",
    "    count = row['IDENTITY'][:12].count(first_12_chars)\n",
    "    if count > 2:\n",
    "        valid_indexes.append(idx)\n",
    "\n",
    "print(\"Train indexes with more than 2 occurrences of the first 12 characters:\", train_indexes)\n",
    "print(\"Validation indexes with more than 2 occurrences of the first 12 characters:\", valid_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac2c9c80c48406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:44:55.386230800Z",
     "start_time": "2024-04-28T21:44:55.312987600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_indexes_size = len(train_indexes)\n",
    "print(train_indexes_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d427699ab4e244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:44:55.897172500Z",
     "start_time": "2024-04-28T21:44:55.844043800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_indexes_size = len(valid_indexes)\n",
    "print(valid_indexes_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a2d2486c1901c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:38:13.800703Z",
     "start_time": "2024-04-28T21:38:13.469176200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "\n",
    "for i in train_indexes:\n",
    "    img_dir = './train_v2/train/' + train.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    train_x.append(image)\n",
    "    \n",
    "    \n",
    "print(f\"Processed {len(train_indexes)} images\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698b5e96cb19c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:40:54.965462400Z",
     "start_time": "2024-04-28T21:40:54.598553300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new data set 66\n",
    "\n",
    "# Reshape the batch into the required format (num_images, height, width, channels)\n",
    "train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n",
    "\n",
    "# Create a folder for the current batch\n",
    "folder_path = os.path.join('dataset', f'{66}')\n",
    "\n",
    "# Save the batch to a .npy file\n",
    "filename = os.path.join(folder_path, f'train_x.npy')\n",
    "np.save(filename, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e6696dff8aaea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:42:36.531994500Z",
     "start_time": "2024-04-28T21:42:34.722046500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_x = []\n",
    "\n",
    "for i in valid_indexes:\n",
    "    img_dir = '.archive/validation_v2/validation/' + valid.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    valid_x.append(image)\n",
    "    \n",
    "print(f\"Processed {len(valid_x)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc621df7754717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:43:09.858927500Z",
     "start_time": "2024-04-28T21:43:09.787672600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new data set 66\n",
    "\n",
    "# Reshape the batch into the required format (num_images, height, width, channels)\n",
    "valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)\n",
    "\n",
    "# Create a folder for the current batch\n",
    "folder_path = os.path.join('dataset', f'{66}')\n",
    "\n",
    "# Save the batch to a .npy file\n",
    "filename = os.path.join(folder_path, f'valid_x.npy')\n",
    "np.save(filename, valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73a0e54e4a1538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:53:34.281673500Z",
     "start_time": "2024-04-28T21:53:34.228999800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize arrays\n",
    "train_y = np.ones([train_indexes_size, max_str_len]) * blank_label\n",
    "train_label_len = np.zeros([train_indexes_size, 1])\n",
    "train_input_len = np.ones([train_indexes_size, 1]) * (num_of_timestamps - 2)\n",
    "train_output = np.zeros([train_indexes_size])\n",
    "\n",
    "# Loop through the training data\n",
    "i = 0\n",
    "for idx in train_indexes:\n",
    "    # Get the 'IDENTITY' value and convert it to a string if it's not already\n",
    "    identity = train.loc[idx, 'IDENTITY']\n",
    "    if not isinstance(identity, str):\n",
    "        identity = str(identity)\n",
    "    \n",
    "    # Set the label length and label values in train_y\n",
    "    train_label_len[i] = len(identity)\n",
    "    \n",
    "    # Assuming label_to_num is a function that converts characters to numerical values\n",
    "    train_y[i, 0:len(identity)] = label_to_num(identity)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de56d43a95f7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:54:02.944749600Z",
     "start_time": "2024-04-28T21:54:02.889714700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save data in the folder\n",
    "folder_path = 'dataset/66'\n",
    "\n",
    "np.save(os.path.join(folder_path, 'train_y.npy'), train_y)\n",
    "np.save(os.path.join(folder_path, 'train_label_len.npy'), train_label_len)\n",
    "np.save(os.path.join(folder_path, 'train_input_len.npy'), train_input_len)\n",
    "np.save(os.path.join(folder_path, 'train_output.npy'), train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7303f9078a62e922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:55:35.974390300Z",
     "start_time": "2024-04-28T21:55:35.918005600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize arrays\n",
    "valid_y = np.ones([valid_indexes_size, max_str_len]) * blank_label\n",
    "valid_label_len = np.zeros([valid_indexes_size, 1])\n",
    "valid_input_len = np.ones([valid_indexes_size, 1]) * (num_of_timestamps - 2)\n",
    "valid_output = np.zeros([valid_indexes_size])\n",
    "\n",
    "# Loop through the training data\n",
    "i = 0\n",
    "for idx in valid_indexes:\n",
    "    # Get the 'IDENTITY' value and convert it to a string if it's not already\n",
    "    identity = valid.loc[idx, 'IDENTITY']\n",
    "    if not isinstance(identity, str):\n",
    "        identity = str(identity)\n",
    "    \n",
    "    # Set the label length and label values in train_y\n",
    "    valid_label_len[i] = len(identity)\n",
    "    \n",
    "    # Assuming label_to_num is a function that converts characters to numerical values\n",
    "    valid_y[i, 0:len(identity)] = label_to_num(identity)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1360c323c7b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T21:56:04.104075200Z",
     "start_time": "2024-04-28T21:56:04.045677100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save data in the folder\n",
    "folder_path = 'dataset/66'\n",
    "\n",
    "np.save(os.path.join(folder_path, 'valid_y.npy'), valid_y)\n",
    "np.save(os.path.join(folder_path, 'valid_label_len.npy'), valid_label_len)\n",
    "np.save(os.path.join(folder_path, 'valid_input_len.npy'), valid_input_len)\n",
    "np.save(os.path.join(folder_path, 'valid_output.npy'), valid_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
